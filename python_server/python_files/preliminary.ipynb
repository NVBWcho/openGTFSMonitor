{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240515\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_id</th>\n",
       "      <th>date</th>\n",
       "      <th>exception_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Special</td>\n",
       "      <td>20240515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>Special#7</td>\n",
       "      <td>20240515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Special#9</td>\n",
       "      <td>20240515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>Special#10</td>\n",
       "      <td>20240515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>Special#12</td>\n",
       "      <td>20240515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005748</th>\n",
       "      <td>Special#16761</td>\n",
       "      <td>20240515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005921</th>\n",
       "      <td>Special#16766</td>\n",
       "      <td>20240515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005959</th>\n",
       "      <td>Special#16768</td>\n",
       "      <td>20240515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006031</th>\n",
       "      <td>Special#16774</td>\n",
       "      <td>20240515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006050</th>\n",
       "      <td>Special#16775</td>\n",
       "      <td>20240515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4326 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            service_id      date  exception_type\n",
       "63             Special  20240515               1\n",
       "543          Special#7  20240515               1\n",
       "760          Special#9  20240515               1\n",
       "928         Special#10  20240515               1\n",
       "1172        Special#12  20240515               1\n",
       "...                ...       ...             ...\n",
       "1005748  Special#16761  20240515               1\n",
       "1005921  Special#16766  20240515               1\n",
       "1005959  Special#16768  20240515               1\n",
       "1006031  Special#16774  20240515               1\n",
       "1006050  Special#16775  20240515               1\n",
       "\n",
       "[4326 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "from sollfahrplanreader.currentdayanalyser import GTFSCurrentDayAnalysis\n",
    "\n",
    "\n",
    "myAnalyser=GTFSCurrentDayAnalysis(os.getcwd())\n",
    "todaysServices=myAnalyser.getTodaysServices()\n",
    "todaysServices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoFlatFileForTodayException",
     "evalue": "Database already filled for current day 2024-05-21 10:23:08",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoFlatFileForTodayException\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnoflatfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoFlatFileForTodayException\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m NoFlatFileForTodayException\n",
      "\u001b[1;31mNoFlatFileForTodayException\u001b[0m: Database already filled for current day 2024-05-21 10:23:08"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from exceptions.noflatfile import NoFlatFileForTodayException\n",
    "\n",
    "raise NoFlatFileForTodayException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GTFSCurrentDayAnalysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01munittest\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m myAnalyser\u001b[38;5;241m=\u001b[39mGTFSCurrentDayAnalysis(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GTFSCurrentDayAnalysis' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import unittest\n",
    "myAnalyser=GTFSCurrentDayAnalysis(os.getcwd())\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "from sollfahrplanreader.currentdayanalyser import GTFSCurrentDayAnalysis\n",
    "\n",
    "class SollFahrplanmethodTester(unittest.TestCase):\n",
    "    \n",
    "   \n",
    "    \n",
    "    def testDateFormtter(self):\n",
    "        todaysDate='20240514'\n",
    "        timeToday='22:30:00'\n",
    "        returedDate=myAnalyser.generateTimeStamp(todaysDate,timeToday)\n",
    "        print(returedDate)\n",
    "        actualTimestamp=datetime.strptime(\"20240514 22:30:00\",\"%Y%m%d %H:%M:%S\")\n",
    "        actualDay=actualTimestamp.day\n",
    "        actualHour=actualTimestamp.hour\n",
    "        actualMinute=actualTimestamp.minute\n",
    "        \n",
    "        self.assertEqual(actualDay,returedDate.day)\n",
    "        self.assertEqual(actualHour,returedDate.hour)\n",
    "        self.assertEqual(actualMinute,returedDate.minute)\n",
    "    def testServiceParser(self):\n",
    "        returnedServices=myAnalyser.getTodaysServices()\n",
    "        numberOfUniqueDays=len(set(list(returnedServices[\"date\"])))\n",
    "        self.assertEqual(numberOfUniqueDays,1)\n",
    "        returnedDay=list(returnedServices[\"date\"])[0]\n",
    "        self.assertEqual(returnedDay,datetime.strftime(datetime.today(),\"%Y%m%d\"))     \n",
    "solllTester=SollFahrplanmethodTester()\n",
    "solllTester.testDateFormtter()\n",
    "\n",
    "solllTester.testServiceParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import pickle\n",
    "from exceptions.databasealredyfilled import DatabaseAlreadyFilledException\n",
    "from getrootdirectory import getRootDirectory\n",
    "from configuration.parameters import ConfigurationParameters\n",
    "\n",
    "\n",
    "        \n",
    "class GTFSCurrentDayAnalysis:\n",
    "    def __init__(self,filePath:str) -> None:\n",
    "        self.parentDirectory=filePath\n",
    "        self.configurationParameters=ConfigurationParameters()\n",
    "    def getTodaysServices(self):\n",
    "        date_parser = lambda x: pd.to_datetime(x, format='%Y%m%d')\n",
    "        dayOfWeek=datetime.now().strftime('%A')\n",
    "        dayOfWeek=dayOfWeek.lower()\n",
    "        calendar_formatted = pd.read_csv(os.path.join(os.getcwd(),\"data\",\"calendar.txt\"), parse_dates=['start_date','end_date'], date_parser=date_parser)\n",
    "        todaysServices=calendar_formatted.loc[((calendar_formatted[\"start_date\"]<date_parser(datetime.today().strftime('%Y%m%d'))) & (calendar_formatted[\"end_date\"]>date_parser(datetime.today().strftime('%Y%m%d'))) & (calendar_formatted[dayOfWeek]==1))]\n",
    "        calendar_dates=pd.read_csv(os.path.join(os.getcwd(),\"data\",\"calendar_dates.txt\"),parse_dates=['date'], date_parser=date_parser)\n",
    "        \n",
    "        includedsServicesServices=calendar_dates.loc[(calendar_dates[\"date\"]==date_parser(datetime.today().strftime('%Y%m%d'))) & (calendar_dates[\"exception_type\"]==1)]\n",
    "    \n",
    "\n",
    "        excludedServvices=calendar_dates.loc[(calendar_dates[\"date\"]==date_parser(datetime.today().strftime('%Y%m%d'))) & (calendar_dates[\"exception_type\"]==2)]\n",
    "        originalServices=set(list(todaysServices[\"service_id\"]))\n",
    "        removedServices=set(list(excludedServvices[\"service_id\"]))\n",
    "        addedServices=set(list(includedsServicesServices[\"service_id\"]))\n",
    "        activeServices=originalServices.difference(removedServices)\n",
    "        activeServices=activeServices.union(addedServices)\n",
    "        todaysServices=pd.DataFrame(columns=[\"service_id\",\"date\"])\n",
    "        todaysServices[\"service_id\"]=list(activeServices)\n",
    "        todaysServices[\"date\"]=[datetime.today().strftime(\"%Y%m%d\")]*len(activeServices)\n",
    "        \n",
    "        return todaysServices\n",
    "    \n",
    "    def getTodaysTrips(self):\n",
    "        todaysServices=self.getTodaysServices()\n",
    "        trips=pd.read_csv(os.path.join(self.parentDirectory,\"data\",\"trips.txt\"))\n",
    "        todayTrips=pd.merge(trips, todaysServices, on='service_id', how='inner')\n",
    "        todayUniqueTripds=todayTrips.drop_duplicates(subset=[\"trip_id\"])\n",
    "        return todayUniqueTripds\n",
    "    \n",
    "    def generateTimeStamp(self,day,time:str):\n",
    "        try:\n",
    "            timestampStr=day+\" \"+time\n",
    "            correct_timestamp=datetime.strptime(timestampStr,\"%Y%m%d %H:%M:%S\")\n",
    "        except:\n",
    "            \n",
    "            timeparts=time.split(\":\")\n",
    "            hours=(timeparts[0])\n",
    "            minutes=int(timeparts[1])\n",
    "            correctedHours=correctedHours=int(hours)-24\n",
    "            current_datetime = datetime.today()\n",
    "\n",
    "                # Set the time to midnight (00:00:00)\n",
    "            beginning_of_tomorrow = current_datetime.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "            correct_timestamp=beginning_of_tomorrow+timedelta(days=1,hours=correctedHours,minutes=minutes)\n",
    "                \n",
    "            \n",
    "        return correct_timestamp\n",
    "    \n",
    "    def getDeparturesAndArrivalsToday(self):\n",
    "        todaysTrips=self.getTodaysTrips()\n",
    "        dtype = {\"date\": str}\n",
    "        stopTimes=pd.read_csv(os.path.join(self.parentDirectory,\"data\",\"stop_times.txt\"),dtype=dtype)\n",
    "        first_stop = stopTimes['stop_sequence'] == 1\n",
    "        last_stop = stopTimes.groupby('trip_id')['stop_sequence'].transform('max') == stopTimes['stop_sequence']\n",
    "        subset = stopTimes[first_stop | last_stop]\n",
    "        subset\n",
    "        \n",
    "        todaysDepartureArrivals=pd.merge(subset,todaysTrips,on=\"trip_id\",how=\"inner\")\n",
    "        todaysDepartureArrivals.sort_values(by=['trip_id', 'stop_sequence'])\n",
    "        todaysDepartureArrivals.to_csv(os.path.join(self.parentDirectory,\"data\",datetime.now().strftime(\"%Y-%m-%d\")+\".txt\"))\n",
    "        \n",
    "        timestamps=[]\n",
    "        agencies=[]\n",
    "        trip_ids=[]\n",
    "        beginTimes=[]\n",
    "        endTimes=[]\n",
    "        agencyFlat=[]\n",
    "        \n",
    "        for i in range(len(todaysDepartureArrivals)):\n",
    "            row=todaysDepartureArrivals.iloc[i]\n",
    "            day=row[\"date\"]\n",
    "            currentTripId=row[\"trip_id\"]\n",
    "            \n",
    "            \n",
    "            if(row[\"stop_sequence\"]==1):\n",
    "                time=row[\"departure_time\"]\n",
    "                timestamp=self.generateTimeStamp(day,time)\n",
    "                beginTimes.append(timestamp)\n",
    "                timestamps.append(timestamp)\n",
    "                trip_ids.append(currentTripId)\n",
    "                agency=row[\"trip_id\"].split(\"-\")[0]\n",
    "                agencyFlat.append(agency)\n",
    "                \n",
    "                \n",
    "                \n",
    "                        \n",
    "                \n",
    "            else:\n",
    "                    \n",
    "                \n",
    "                time=row[\"arrival_time\"]\n",
    "                timestamp=self.generateTimeStamp(day,time)\n",
    "                endTimes.append(timestamp)\n",
    "                timestamps.append(timestamp)\n",
    "                \n",
    "                \n",
    "                \n",
    "              \n",
    "                \n",
    "            agency=row[\"trip_id\"].split(\":\")[0]\n",
    "            agencies.append(agency)\n",
    "            \n",
    "           \n",
    "                    \n",
    "            \n",
    "        todaysDepartureArrivals[\"timestamp\"]=timestamps\n",
    "        todaysDepartureArrivals[\"agency\"]=agencies\n",
    "       \n",
    "        \n",
    "        flatDataset=pd.DataFrame(columns=[\"trip_id\",\"begin_time\",\"end_time\",\"agency\"])\n",
    "        flatDataset[\"trip_id\"]=trip_ids\n",
    "        flatDataset[\"begin_time\"]=beginTimes\n",
    "        flatDataset[\"end_time\"]=endTimes\n",
    "        flatDataset[\"agency\"]=agencyFlat\n",
    "        flatDataset[\"number of updates\"]=[0]*len(trip_ids)\n",
    "        flatDataset.to_pickle(os.path.join(self.parentDirectory,\"data\",\"flat\"+datetime.now().strftime(\"%Y-%m-%d\")+\".pkl\"))\n",
    "        #flatDataset.to_pickle(\"today_flat\"+\".pkl\")\n",
    "        flatDataset.to_csv(os.path.join(self.parentDirectory,\"data\",\"flat\"+datetime.now().strftime(\"%Y-%m-%d\")+\".txt\"))\n",
    "        \n",
    "        todaySubset= todaysDepartureArrivals[[\"trip_id\",\"arrival_time\", \"departure_time\", \"stop_id\",\"stop_sequence\",\n",
    "                                        \"stop_headsign\",\"route_id\", \"service_id\",\"trip_headsign\",\"direction_id\",\n",
    "                                        \"date\", \"timestamp\", \"agency\"]]\n",
    "        todaySubset[\"minute of day\"]=todaySubset['timestamp'].dt.hour * 60 + todaySubset['timestamp'].dt.minute\n",
    "        todaySubset.to_pickle(os.path.join(self.parentDirectory,\"data\",datetime.now().strftime(\"%Y-%m-%d\")+\".pkl\"))\n",
    "        return flatDataset\n",
    "    \n",
    "    def getVolumeSumaryByMinute(self):\n",
    "        df=self.getDeparturesAndArrivalsToday()[1]\n",
    "        df['begin_time'] = pd.to_datetime(df['begin_time'])\n",
    "        df['end_time'] = pd.to_datetime(df['end_time'])\n",
    "\n",
    "        # Generate a list of unique timestamps within the range of 'begin_time' and 'end_time'\n",
    "        all_timestamps = pd.date_range(start=df['begin_time'].min().floor('T'), end=df['end_time'].max().ceil('T'), freq='T')\n",
    "\n",
    "        # Initialize a dictionary to store the count of active trips for each timestamp\n",
    "        active_trips_count = {}\n",
    "\n",
    "        # Iterate over each timestamp and count the number of active trips\n",
    "        for timestamp in all_timestamps:\n",
    "            active_trips_count[timestamp] = ((df['begin_time'] <= timestamp) & (timestamp <= df['end_time'])).sum()\n",
    "\n",
    "        # Create a new DataFrame from the dictionary of active trips counts\n",
    "        active_trips_df = pd.DataFrame.from_dict(active_trips_count, orient='index', columns=['active_trips_count'])\n",
    "\n",
    "        # Reset the index to have timestamp as a column\n",
    "        active_trips_df = active_trips_df.reset_index().rename(columns={'index': 'timestamp'})\n",
    "\n",
    "        # Display the resulting DataFrame\n",
    "        active_trips_df.to_pickle(\"minuteSummary\"+datetime.now().strftime(\"%Y-%m-%d\")+\".pkl\")\n",
    "        return active_trips_df\n",
    "    \n",
    "    def prepareSQLStatmentForTrip(self,tripDetailsRow):\n",
    "        sqlStatement='INSERT INTO schedule_updates(trip_id, begin_time, end_time, agency,number_of_updates) VALUES ({trip_id}, {begin_time},{end_time},{agency},{number_of_updates});'.format(trip_id=tripDetailsRow[\"trip_id\"],begin_time=tripDetailsRow[\"begin_time\"],end_time=tripDetailsRow[\"end_time\"],agency=tripDetailsRow[\"agency\"],number_of_updates=0)\n",
    "        return sqlStatement\n",
    "    \n",
    "    def checkIfDatabaseAlreadyFilled(self):\n",
    "        rootPath=getRootDirectory()\n",
    "        try:\n",
    "            with open(os.path.join(rootPath,\"data\",\"flat\"+datetime.now().strftime(\"%Y-%m-%d\")+\".pkl\"), 'rb') as file:\n",
    "                flat_df = pickle.load(file)\n",
    "                return True\n",
    "        except:\n",
    "            return False\n",
    "                    \n",
    "        \n",
    "        \n",
    "       \n",
    "    \n",
    "    def writeToDatabase(self):\n",
    "        \n",
    "        alreadyFilled=self.checkIfDatabaseAlreadyFilled()\n",
    "        if(alreadyFilled):\n",
    "            raise DatabaseAlreadyFilledException\n",
    "        \n",
    "        todaysTrips=self.getDeparturesAndArrivalsToday()\n",
    "        databasename=self.configurationParameters.databasename\n",
    "        conn = psycopg2.connect(\n",
    "    database=databasename, user='postgres', password='postgres', host='127.0.0.1', port= '5432'\n",
    "                           )\n",
    "        cursor = conn.cursor()\n",
    "        for i in range(len(todaysTrips)):\n",
    "            currentRow=todaysTrips.iloc[i]\n",
    "            sqlStatement=\"INSERT INTO schedule_updates(trip_id, begin_time, end_time, agency,number_of_updates) VALUES (%s, %s, %s, %s, %s)\"\n",
    "            values=(currentRow[\"trip_id\"],currentRow[\"begin_time\"],currentRow[\"end_time\"],currentRow[\"agency\"],0)\n",
    "\n",
    "\n",
    "            cursor.execute(sqlStatement,values)\n",
    "            \n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHO\\Documents\\GTFSRTAnalysis\\migtfsanalysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CHO\\AppData\\Local\\Temp\\ipykernel_18824\\472086160.py:20: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  calendar_formatted = pd.read_csv(os.path.join(os.getcwd(),\"data\",\"calendar.txt\"), parse_dates=['start_date','end_date'], date_parser=date_parser)\n",
      "C:\\Users\\CHO\\AppData\\Local\\Temp\\ipykernel_18824\\472086160.py:22: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  calendar_dates=pd.read_csv(os.path.join(os.getcwd(),\"data\",\"calendar_dates.txt\"),parse_dates=['date'], date_parser=date_parser)\n",
      "C:\\Users\\CHO\\AppData\\Local\\Temp\\ipykernel_18824\\472086160.py:69: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  stopTimes=pd.read_csv(os.path.join(self.parentDirectory,\"data\",\"stop_times.txt\"),dtype=dtype)\n",
      "C:\\Users\\CHO\\AppData\\Local\\Temp\\ipykernel_18824\\472086160.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  todaySubset[\"minute of day\"]=todaySubset['timestamp'].dt.hour * 60 + todaySubset['timestamp'].dt.minute\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>begin_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>agency</th>\n",
       "      <th>number of updates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AKT:ServiceJourney:100_1_104_281_51_118800_123...</td>\n",
       "      <td>2024-06-17 16:30:00</td>\n",
       "      <td>2024-06-17 17:55:00</td>\n",
       "      <td>AKT:ServiceJourney:100_1_104_281_51_118800_123...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AKT:ServiceJourney:100_1_112_291_51_126000_131...</td>\n",
       "      <td>2024-06-17 17:30:00</td>\n",
       "      <td>2024-06-17 18:55:00</td>\n",
       "      <td>AKT:ServiceJourney:100_1_112_291_51_126000_131...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AKT:ServiceJourney:100_1_116_301_69_131400_136...</td>\n",
       "      <td>2024-06-17 18:15:00</td>\n",
       "      <td>2024-06-17 19:45:00</td>\n",
       "      <td>AKT:ServiceJourney:100_1_116_301_69_131400_136...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AKT:ServiceJourney:100_1_11_71_51_50400_55500_...</td>\n",
       "      <td>2024-06-17 07:00:00</td>\n",
       "      <td>2024-06-17 08:25:00</td>\n",
       "      <td>AKT:ServiceJourney:100_1_11_71_51_50400_55500_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AKT:ServiceJourney:100_1_122_311_69_138600_144...</td>\n",
       "      <td>2024-06-17 19:15:00</td>\n",
       "      <td>2024-06-17 20:45:00</td>\n",
       "      <td>AKT:ServiceJourney:100_1_122_311_69_138600_144...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             trip_id          begin_time  \\\n",
       "0  AKT:ServiceJourney:100_1_104_281_51_118800_123... 2024-06-17 16:30:00   \n",
       "1  AKT:ServiceJourney:100_1_112_291_51_126000_131... 2024-06-17 17:30:00   \n",
       "2  AKT:ServiceJourney:100_1_116_301_69_131400_136... 2024-06-17 18:15:00   \n",
       "3  AKT:ServiceJourney:100_1_11_71_51_50400_55500_... 2024-06-17 07:00:00   \n",
       "4  AKT:ServiceJourney:100_1_122_311_69_138600_144... 2024-06-17 19:15:00   \n",
       "\n",
       "             end_time                                             agency  \\\n",
       "0 2024-06-17 17:55:00  AKT:ServiceJourney:100_1_104_281_51_118800_123...   \n",
       "1 2024-06-17 18:55:00  AKT:ServiceJourney:100_1_112_291_51_126000_131...   \n",
       "2 2024-06-17 19:45:00  AKT:ServiceJourney:100_1_116_301_69_131400_136...   \n",
       "3 2024-06-17 08:25:00  AKT:ServiceJourney:100_1_11_71_51_50400_55500_...   \n",
       "4 2024-06-17 20:45:00  AKT:ServiceJourney:100_1_122_311_69_138600_144...   \n",
       "\n",
       "   number of updates  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from getrootdirectory import getRootDirectory\n",
    "myAnalyser=GTFSCurrentDayAnalysis(getRootDirectory())\n",
    "todaysTrips=myAnalyser.getDeparturesAndArrivalsToday()\n",
    "todaysTrips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20240614', '20240614', '20240614']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "d=datetime.today().strftime(\"%Y%m%d\")\n",
    "l=[d]*3\n",
    "l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
